{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "statistical project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dpev2pPehmt"
      },
      "source": [
        "#Setiment analysis of bitcoin with tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iodeMWbf9a8c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import *\n",
        "import cvxpy as cp\n",
        "from math import log, exp\n",
        "import numpy as np\n",
        "from numpy.random import random\n",
        "import time\n",
        "#import cvxopt, cvxopt.solvers\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qDMCzw7B3Tb",
        "outputId": "f04c89ec-7645-4b5c-efa0-368ce139b536"
      },
      "source": [
        "!pip install pandas OpenBlender scikit-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting OpenBlender\n",
            "  Downloading OpenBlender-2.11.tar.gz (6.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-4.3-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from OpenBlender) (2.23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->OpenBlender) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->OpenBlender) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->OpenBlender) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->OpenBlender) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface->datetime->OpenBlender) (57.4.0)\n",
            "Building wheels for collected packages: OpenBlender\n",
            "  Building wheel for OpenBlender (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for OpenBlender: filename=OpenBlender-2.11-py3-none-any.whl size=6654 sha256=204f6a977fbc668a4e2a1a98b9a0e687b5d2895ac9f46b60a5987e807c1ab621\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/ab/44/d9bd09091ae990c19555441e9baf3fc7794b330fa89c90f3a8\n",
            "Successfully built OpenBlender\n",
            "Installing collected packages: zope.interface, datetime, OpenBlender\n",
            "Successfully installed OpenBlender-2.11 datetime-4.3 zope.interface-5.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_IoA4iuCcP6",
        "outputId": "27a443a7-0bc6-46ab-df6b-f859f2a5010a"
      },
      "source": [
        "!pip install fsspec"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 132 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "Successfully installed fsspec-2021.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtCmAEH_UTnJ"
      },
      "source": [
        "# the preprocessing codes and vectorizing are already suggested by open blender and can be found at the references below:\n",
        "##https://www.openblender.io/#/dataset/blend/5d4c3af79516290b01c83f51/ts\n",
        "\n",
        "##https://towardsdatascience.com/predict-any-cryptocurrency-applying-nlp-with-global-news-e938af6f7922\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PPygdNQweZJ",
        "outputId": "9029b528-dfd1-4c7f-8aba-3da40dad334c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import OpenBlender\n",
        "import json\n",
        "token = '61ab6ed9951629523799cc8bDZRKyA5X51hyJGbuNh0W4MUi2WAJre'\n",
        "action = 'API_getObservationsFromDataset'\n",
        "\n",
        "  \n",
        "parameters = { \n",
        "    'token' : token,\n",
        "    'id_dataset' : '5d4c3af79516290b01c83f51',\n",
        "    'date_filter':{\"start_date\" : \"2010-01-01\",\n",
        "                   \"end_date\" : \"2021-08-29\"} \n",
        "\t\t#'aggregate_in_time_interval':{\"time_interval_size\":86400,\"output\":\"avg\",\"empty_intervals\":\"impute\"} \n",
        "}\n",
        "df = pd.read_json(json.dumps(OpenBlender.call(action, parameters)['sample']), convert_dates=False, convert_axes=False).sort_values('timestamp', ascending=False)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df['date'] = [OpenBlender.unixToDate(ts, timezone = 'GMT') for ts in df.timestamp]\n",
        "df = df.drop('timestamp', axis = 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task ID: '61ab6f0b0895fafb4a9d8d4b'.\n",
            "Total estimated consumption: 500.28 processing units.\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "100.0 % completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7obCQir5o32S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93783f8-823c-48cb-95b7-a795ef9ca130"
      },
      "source": [
        "df.size"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19677"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KmLfkQ2DBcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59864ea3-757f-49c2-c869-695f857b4ad5"
      },
      "source": [
        "y1=np.log(df['open'])\n",
        "y2=np.log(df['price'])\n",
        "df['difference'] = y2-y1 \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcLVEvLkDSEl"
      },
      "source": [
        "df['target'] = [1 if difference > 0 else 0 for difference in df['difference']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7_VNxJ1DYwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "05a2cc1c-eeba-44cd-d99f-dc76de2f9d0f"
      },
      "source": [
        "format = '%d-%m-%Y %H:%M:%S'\n",
        "timezone = 'GMT'\n",
        "df['timestamp'] = OpenBlender.dateToUnix(df['date'], \n",
        "                                           date_format = format, \n",
        "                                           timezone = timezone)\n",
        "df = df[['timestamp', 'date', 'price', 'target']]\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.629652e+09</td>\n",
              "      <td>22-08-2021 17:00:00</td>\n",
              "      <td>49264.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.620925e+09</td>\n",
              "      <td>13-05-2021 17:00:00</td>\n",
              "      <td>49747.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.620839e+09</td>\n",
              "      <td>12-05-2021 17:00:00</td>\n",
              "      <td>49725.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.620752e+09</td>\n",
              "      <td>11-05-2021 17:00:00</td>\n",
              "      <td>56715.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.620666e+09</td>\n",
              "      <td>10-05-2021 17:00:00</td>\n",
              "      <td>55851.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      timestamp                 date    price  target\n",
              "0  1.629652e+09  22-08-2021 17:00:00  49264.0       1\n",
              "1  1.620925e+09  13-05-2021 17:00:00  49747.0       1\n",
              "2  1.620839e+09  12-05-2021 17:00:00  49725.0       0\n",
              "3  1.620752e+09  11-05-2021 17:00:00  56715.0       1\n",
              "4  1.620666e+09  10-05-2021 17:00:00  55851.0       0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdGqz9C2DiPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed28792-4fd8-4bc0-8652-6a4f091a6d67"
      },
      "source": [
        "search_keyword = 'bitcoin'\n",
        "df = df.sort_values('timestamp').reset_index(drop = True)\n",
        "OpenBlender.searchTimeBlends(token,\n",
        "                             df.timestamp,\n",
        "                             search_keyword)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'description': 'Daily prices and volumes for the digital currency BitcoinsCash.',\n",
              "  'features': ['close',\n",
              "   'high',\n",
              "   'low',\n",
              "   'market_cap',\n",
              "   'open',\n",
              "   'timestamp',\n",
              "   'volume'],\n",
              "  'id_dataset': '5d9f899b951629329a748593',\n",
              "  'intersection': 47.264299203655526,\n",
              "  'name': 'Bitcoins Cash Historical data',\n",
              "  'num_observations': 1580,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5d9f899b951629329a748593'},\n",
              " {'description': '',\n",
              "  'features': ['date',\n",
              "   'feargreed_index',\n",
              "   'feargreed_classification',\n",
              "   'bitcoin_search',\n",
              "   'coinbase_search',\n",
              "   'crypto_search',\n",
              "   'ethereum_search'],\n",
              "  'id_dataset': '6114e0ed9516295907e7f5d4',\n",
              "  'intersection': 41.16295347393722,\n",
              "  'name': 'BTC Fear&Greed   Google Analyst weekly searches',\n",
              "  'num_observations': 1288,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/6114e0ed9516295907e7f5d4'},\n",
              " {'description': '',\n",
              "  'features': ['settimana', 'bitcoin', 'coinbase', 'crypto', 'ethereum'],\n",
              "  'id_dataset': '6114d7009516295906ef5474',\n",
              "  'intersection': 41.06786756646109,\n",
              "  'name': 'Crypto google search weekly trend',\n",
              "  'num_observations': 184,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/6114d7009516295906ef5474'},\n",
              " {'description': 'Daily Price of Bitcoin Diamond',\n",
              "  'features': ['change',\n",
              "   'high',\n",
              "   'low',\n",
              "   'open',\n",
              "   'price',\n",
              "   'timestamp',\n",
              "   'volume'],\n",
              "  'id_dataset': '5db7ab619516294f40b8cb94',\n",
              "  'intersection': 21.908057210021,\n",
              "  'name': 'Bitcoin Diamond Price',\n",
              "  'num_observations': 761,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5db7ab619516294f40b8cb94'},\n",
              " {'description': 'Daily Price of Bitcoin SV',\n",
              "  'features': ['change',\n",
              "   'high',\n",
              "   'low',\n",
              "   'open',\n",
              "   'price',\n",
              "   'timestamp',\n",
              "   'volume'],\n",
              "  'id_dataset': '5db7a7c99516294f3f6c2faf',\n",
              "  'intersection': 20.988893437751745,\n",
              "  'name': 'Bitcoin SV Price',\n",
              "  'num_observations': 704,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5db7a7c99516294f3f6c2faf'},\n",
              " {'description': 'Daily Price of Bitcoin Gold',\n",
              "  'features': ['change',\n",
              "   'high',\n",
              "   'low',\n",
              "   'open',\n",
              "   'price',\n",
              "   'timestamp',\n",
              "   'volume'],\n",
              "  'id_dataset': '5db7aa0b9516294f3f6c30ca',\n",
              "  'intersection': 20.988893437751745,\n",
              "  'name': 'Bitcoin Gold Price',\n",
              "  'num_observations': 706,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5db7aa0b9516294f3f6c30ca'},\n",
              " {'description': 'The latest Twitter threads from Coinnounce  Bitcoin  Altcoin News (coinnounce). We cover bitcoin and altcoin news 247.',\n",
              "  'features': ['associated_tweet',\n",
              "   'author',\n",
              "   'author_id',\n",
              "   'favorite_count',\n",
              "   'hashtags',\n",
              "   'id',\n",
              "   'links',\n",
              "   'mentions',\n",
              "   're_tweeter',\n",
              "   'reply_count',\n",
              "   'retweet_count',\n",
              "   'text',\n",
              "   'time',\n",
              "   'type'],\n",
              "  'id_dataset': '5ea20ec595162936337159b4',\n",
              "  'intersection': 20.833806194964264,\n",
              "  'name': 'Coinnounce  Bitcoin  Altcoin News Tweet',\n",
              "  'num_observations': 219,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5ea20ec595162936337159b4'},\n",
              " {'description': 'The latest Twitter threads from Bitcoin News (@BTCTN). Official Twitter account for http://news.bitcoin.com/',\n",
              "  'features': ['associated_tweet',\n",
              "   'author',\n",
              "   'author_id',\n",
              "   'favorite_count',\n",
              "   'hashtags',\n",
              "   'id',\n",
              "   'links',\n",
              "   'mentions',\n",
              "   're_tweeter',\n",
              "   'reply_count',\n",
              "   'retweet_count',\n",
              "   'text',\n",
              "   'time',\n",
              "   'type'],\n",
              "  'id_dataset': '5ea2039095162936337156c9',\n",
              "  'intersection': 19.005864364648588,\n",
              "  'name': 'Bitcoin News Tweet',\n",
              "  'num_observations': 9909,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5ea2039095162936337156c9'},\n",
              " {'description': 'The latest Twitter threads from CoinJournal (@CoinJournal).',\n",
              "  'features': ['associated_tweet',\n",
              "   'author',\n",
              "   'author_id',\n",
              "   'favorite_count',\n",
              "   'hashtags',\n",
              "   'id',\n",
              "   'links',\n",
              "   'mentions',\n",
              "   're_tweeter',\n",
              "   'reply_count',\n",
              "   'retweet_count',\n",
              "   'text',\n",
              "   'time',\n",
              "   'type'],\n",
              "  'id_dataset': '5ea20b4e95162936348f141d',\n",
              "  'intersection': 18.846165895561043,\n",
              "  'name': 'CoinJournal Tweet',\n",
              "  'num_observations': 2183,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5ea20b4e95162936348f141d'},\n",
              " {'description': 'Daily exchange rate of US dollar vs Bitcoin',\n",
              "  'features': ['price', 'timestamp'],\n",
              "  'id_dataset': '5e83717095162945e8ae242c',\n",
              "  'intersection': 16.124466257506327,\n",
              "  'name': 'Bitcoin vs USD hot',\n",
              "  'num_observations': 2960,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/5e83717095162945e8ae242c'},\n",
              " {'description': 'Bitcoin historical prices adn marketcap. Powered by CoinGecko API',\n",
              "  'features': ['marketcap', 'price', 'timestamp'],\n",
              "  'id_dataset': '608a409b95162942292e1ca2',\n",
              "  'intersection': 3.197261387636621,\n",
              "  'name': 'Bitcoin prices',\n",
              "  'num_observations': 18948,\n",
              "  'url': 'https://www.openblender.io/#/dataset/explore/608a409b95162942292e1ca2'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04juixNRlUn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeeb3e9c-fb26-429f-f852-220985925124"
      },
      "source": [
        "pos = {'name' : 'positive', \n",
        "                   'match_ngrams': ['positive', 'buy', \n",
        "                                    'bull', 'boost']}\n",
        "blend_source = {\n",
        "                'id_dataset':'5ea2039095162936337156c9',\n",
        "                'feature' : 'text',\n",
        "                'filter_text' : pos\n",
        "            }\n",
        "df11= OpenBlender.timeBlend( token = token,\n",
        "                                  anchor_ts = df.timestamp,\n",
        "                                  blend_source = blend_source,\n",
        "                                  blend_type = 'agg_in_intervals',\n",
        "                                  interval_size = 60 * 60 * 24,\n",
        "                                  direction = 'time_prior',\n",
        "                                  interval_output = 'list',\n",
        "                                  missing_values = 'raw')\n",
        "df=pd.concat([df, df11.loc[:, df11.columns != 'timestamp']], axis = 1)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task ID: '61ab6f110895fafb4a9d8d4c'.\n",
            "Total estimated consumption: 9795.2 processing units.\n",
            "Task confirmed. Starting download..\n",
            "36.0%\n",
            "71.0%\n",
            "100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBEg1leuIkHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106fbcf9-18a8-4714-c7c2-c9fdb9634a1d"
      },
      "source": [
        "\n",
        "neg = {'name' : 'negative', \n",
        "                   'match_ngrams': ['negative', 'loss', 'drop', 'plummet', 'sell', 'fundraising']}\n",
        "blend_source = {\n",
        "                'id_dataset':'5ea2039095162936337156c9',\n",
        "                'feature' : 'text',\n",
        "                'filter_text' : neg\n",
        "            }\n",
        "df22 = OpenBlender.timeBlend( token = token,\n",
        "                                  anchor_ts = df.timestamp,\n",
        "                                  blend_source = blend_source,\n",
        "                                  blend_type = 'agg_in_intervals',\n",
        "                                  interval_size = 60 * 60 * 24,\n",
        "                                  direction = 'time_prior',\n",
        "                                  interval_output = 'list',\n",
        "                                  missing_values = 'raw')\n",
        "df=pd.concat([df, df22.loc[:, df22.columns != 'timestamp']], axis = 1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task ID: '61ab6f1b0895fafb4a9d8d4c'.\n",
            "Total estimated consumption: 9795.2 processing units.\n",
            "Task confirmed. Starting download..\n",
            "36.0%\n",
            "71.0%\n",
            "100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z35bz6MloEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "e7e0cd01-71be-42c9-853a-6d5f24cb01d7"
      },
      "source": [
        "df.head(2500)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>target</th>\n",
              "      <th>BITCOIN_NE.text_COUNT_last1days:positive</th>\n",
              "      <th>BITCOIN_NE.text_last1days:positive</th>\n",
              "      <th>BITCOIN_NE.text_last1days:negative</th>\n",
              "      <th>BITCOIN_NE.text_COUNT_last1days:negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.357056e+09</td>\n",
              "      <td>01-01-2013 16:00:00</td>\n",
              "      <td>13.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.357142e+09</td>\n",
              "      <td>02-01-2013 16:00:00</td>\n",
              "      <td>13.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.357229e+09</td>\n",
              "      <td>03-01-2013 16:00:00</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.357315e+09</td>\n",
              "      <td>04-01-2013 16:00:00</td>\n",
              "      <td>13.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.357402e+09</td>\n",
              "      <td>05-01-2013 16:00:00</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>1.587661e+09</td>\n",
              "      <td>23-04-2020 17:00:00</td>\n",
              "      <td>7495.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[facebook buys stake in reliance jio  how the ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>1.587748e+09</td>\n",
              "      <td>24-04-2020 17:00:00</td>\n",
              "      <td>7506.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>1.587834e+09</td>\n",
              "      <td>25-04-2020 17:00:00</td>\n",
              "      <td>7538.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>1.587920e+09</td>\n",
              "      <td>26-04-2020 17:00:00</td>\n",
              "      <td>7697.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>1.588007e+09</td>\n",
              "      <td>27-04-2020 17:00:00</td>\n",
              "      <td>7777.7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         timestamp  ... BITCOIN_NE.text_COUNT_last1days:negative\n",
              "0     1.357056e+09  ...                                        0\n",
              "1     1.357142e+09  ...                                        0\n",
              "2     1.357229e+09  ...                                        0\n",
              "3     1.357315e+09  ...                                        0\n",
              "4     1.357402e+09  ...                                        0\n",
              "...            ...  ...                                      ...\n",
              "2495  1.587661e+09  ...                                        0\n",
              "2496  1.587748e+09  ...                                        0\n",
              "2497  1.587834e+09  ...                                        0\n",
              "2498  1.587920e+09  ...                                        0\n",
              "2499  1.588007e+09  ...                                        0\n",
              "\n",
              "[2500 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EHK3fs7MeA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc358bf-1d47-4be4-8519-c9154ed8155c"
      },
      "source": [
        "features = ['target', 'BITCOIN_NE.text_COUNT_last1days:positive', 'BITCOIN_NE.text_COUNT_last1days:negative']\n",
        "df[features].corr()['target']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target                                      1.000000\n",
              "BITCOIN_NE.text_COUNT_last1days:positive    0.031512\n",
              "BITCOIN_NE.text_COUNT_last1days:negative    0.013848\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YzrxAaVMwKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edc89fe-75df-4d64-86a4-0b14ed114455"
      },
      "source": [
        "\n",
        "blend_source = { \n",
        "                'id_textVectorizer':'5f739fe7951629649472e167'\n",
        "               }\n",
        "df33 = OpenBlender.timeBlend( token = token,\n",
        "                                  anchor_ts = df.timestamp,\n",
        "                                  blend_source = blend_source,\n",
        "                                  blend_type = 'agg_in_intervals',\n",
        "                                  interval_size = 60 * 60 * 24,\n",
        "                                  direction = 'time_prior',\n",
        "                                  interval_output = 'list',\n",
        "                                  missing_values = 'raw') .add_prefix('VEC.')\n",
        "df1 = pd.concat([df, df33.loc[:, df33.columns != 'timestamp']], axis = 1)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task ID: '61ab6f270895fafb4a9d8d4c'.\n",
            "Total estimated consumption: 9796.9 processing units.\n",
            "Task confirmed. Starting download..\n",
            "12.0%\n",
            "25.0%\n",
            "37.0%\n",
            "50.0%\n",
            "62.0%\n",
            "75.0%\n",
            "87.0%\n",
            "100.0%\n",
            "100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIeEMoKaNP4S"
      },
      "source": [
        "X = df1.loc[:, df1.columns == 'target'].select_dtypes(include=[np.number]).values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRul_o4wNbTw"
      },
      "source": [
        "\n",
        "correlation = df1.corr().abs()\n",
        "Higher = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(np.bool))\n",
        "for column in Higher.columns:\n",
        "  if any(Higher[column] > 0.5):\n",
        "    df1.drop(column, axis=1, inplace=True)\n",
        "X = df1.loc[:, df1.columns == 'target'].select_dtypes(include=[np.number]).values\n",
        "y = df1.loc[:,['target']].values\n",
        "D = int(round(len(X) * 0.2))\n",
        "X_train = X[:D]\n",
        "y_train = y[:D]\n",
        "X_test = X[D:]\n",
        "y_test = y[D:]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NicFANM5eKUN"
      },
      "source": [
        "##NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWyR6BdpR4yZ"
      },
      "source": [
        "class neuralnetwork():\n",
        "    \n",
        "    def __init__(self,X,Y,X_test,Y_test,Layer,NL):\n",
        "    \n",
        "        self.loss_training = list()\n",
        "        self.accuracy_train = list()\n",
        "        self.loss_testing = list()\n",
        "        self.accuracy_testing = list()\n",
        "        self.X = np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
        "        self.Y = np.squeeze(np.eye(10)[Y.astype(np.int).reshape(-1)])\n",
        "        self.X_test = np.concatenate((X_test,np.ones((X_test.shape[0],1))),axis=1)\n",
        "        self.Y_test = np.squeeze(np.eye(10)[Y_test.astype(np.int).reshape(-1)])\n",
        "        self.Layer = Layer\n",
        "        self.NL = NL\n",
        "        self.ns = self.X.shape[0]\n",
        "        self.layersizes =np.array([self.X.shape[1]]+[NL]*Layer+[self.Y.shape[1]]) \n",
        "        self.initialize_weights()\n",
        "        self.metrics=[self.loss_training,self.accuracy_testing]\n",
        "    def sigmoid(self,x):\n",
        "        AF1=1./(1.+np.exp(-x))\n",
        "        return AF1\n",
        "    \n",
        "    def softmax(self,x):\n",
        "      dd = np.exp(x)\n",
        "      AF2=dd/dd.sum(axis=1,keepdims=True)\n",
        "      return AF2\n",
        "  \n",
        "    def LOSS(self,y_pred,y):\n",
        "        dd=(-np.log(y_pred))*y\n",
        "        Loss=(dd).sum(axis=1).mean()\n",
        "        return Loss\n",
        "    \n",
        "    def accuracy(self,predicted_y,y):  \n",
        "        ACCURACY=np.all(predicted_y==y,axis=1).mean()\n",
        "        return ACCURACY\n",
        "\n",
        "    \n",
        "    def sigmoid_derivation(self,K):\n",
        "        P=K*(1-K)\n",
        "        return P\n",
        "    \n",
        "    def categorical(self,x):  \n",
        "        cat = np.zeros((x.shape[0],self.Y.shape[1]))\n",
        "        catego=cat[np.arange(x.shape[0]),x.argmax(axis=1)] = 1\n",
        "        return catego\n",
        "    \n",
        "    def initialize_weights(self):\n",
        "        self.weights = list()\n",
        "        for i in range(self.layersizes.shape[0]-1):\n",
        "            self.weights.append(np.random.uniform(-1,1,size=[self.layersizes[i],self.layersizes[i+1]]))\n",
        "        self.weights = np.asarray(self.weights)\n",
        "    \n",
        "    def initialize_layer(self,batch_s):\n",
        "        self.hidden = [np.empty((batch_s,layer)) for layer in self.layersizes]\n",
        "    \n",
        "    def feedforward(self,batch):\n",
        "        hiddenlayer = batch\n",
        "        self.hidden[0] = hiddenlayer\n",
        "        for i,weights in enumerate(self.weights):\n",
        "            hiddenlayer = self.sigmoid(hiddenlayer.dot(weights))\n",
        "            self.hidden[i+1]=hiddenlayer\n",
        "        self.o1 = self.softmax(self.hidden[-1])\n",
        "    \n",
        "    def backprop(self,y_batch):\n",
        "        DT = (self.o1 - y_batch)*self.sigmoid_derivation(self.hidden[-1])\n",
        "        for i in range(1,len(self.weights)+1):\n",
        "            self.weights[-i]-=self.learning_rate*(self.hidden[-i-1].T.dot(DT))/self.batch_s\n",
        "            DT = self.sigmoid_derivation(self.hidden[-i-1])*(DT.dot(self.weights[-i].T))\n",
        "            \n",
        "    def prediction_xx(self,X):\n",
        "        x_new=np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
        "        self.initialize_layer(x_new.shape[0])\n",
        "        self.feedforward(x_new)\n",
        "        output1=self.categorical(self.o1)\n",
        "        return output1\n",
        "\n",
        "    \n",
        "    def evaluating(self,X,Y):\n",
        "\n",
        "        predicted_x  = self.prediction_xx(X)\n",
        "        ACC=self.accuracy(predicted_x ,Y)\n",
        "        return ACC\n",
        "        \n",
        "    def training(self,batch_s=8,epochs=25,learning_rate=1.0):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_s=batch_s\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            start = time.time()\n",
        "            \n",
        "            self.initialize_layer(self.batch_s)\n",
        "            shuffle = np.random.permutation(self.ns)\n",
        "            loss_training = 0\n",
        "            accuracy_train = 0\n",
        "            x_batches = np.array_split(self.X[shuffle],self.ns/self.batch_s)\n",
        "            y_batches = np.array_split(self.Y[shuffle],self.ns/self.batch_s)\n",
        "            for batch_x,batch_y in zip(x_batches,y_batches):\n",
        "                self.feedforward(batch_x)  \n",
        "                loss_training += self.LOSS(self.o1,batch_y)\n",
        "                accuracy_train += self.accuracy(self.categorical(self.o1),batch_y)\n",
        "                self.backprop(batch_y)\n",
        "                \n",
        "            loss_training = (loss_training/len(x_batches))\n",
        "            accuracy_train = (accuracy_train/len(x_batches))\n",
        "            self.loss_training.append(loss_training)\n",
        "            self.accuracy_train.append(accuracy_train)\n",
        "\n",
        "            self.initialize_layer(self.X_test.shape[0])\n",
        "            self.feedforward(self.X_test)\n",
        "            loss_testing = self.LOSS(self.o1,self.Y_test)\n",
        "            accuracy_testing = self.accuracy(self.categorical(self.o1),self.Y_test)\n",
        "            self.loss_testing.append(loss_testing)\n",
        "            self.accuracy_testing.append(accuracy_testing)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RmGqtgvXdDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf11a15-de6e-43fb-e0a3-5d4dd6e52893"
      },
      "source": [
        "model = neuralnetwork(X_train,y_train,X_test,y_test,15,128)\n",
        "model.training(batch_s=8,epochs=1,learning_rate=0.01)\n",
        "y_pred = model.prediction_xx(X_test)\n",
        "\n",
        "print('Accuracy Score:')\n",
        "print(model.evaluating(X_test,y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:\n",
            "0.5251222765673633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuXSo-uneRb3"
      },
      "source": [
        "##SUPPORT VECTOR MACHINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Kte9KovaeN"
      },
      "source": [
        "\n",
        "from sys import exit\n",
        "\n",
        "class SVM():  \n",
        "    def initialization(self):\n",
        "            self.params = None\n",
        "            self.support_vector_machine = None\n",
        "            self.std = None\n",
        "            self.kernel_p=None\n",
        "    def kernel(self, x1, x2):\n",
        "            covariance=x1@x2.T\n",
        "            return covariance\n",
        "    def normalization(self, x, set_value=False):\n",
        "            if set_value: self.std = x.std(axis=0) \n",
        "            norm=x/self.std       \n",
        "            return norm\n",
        "    def train(self, x, y, c=1, eta=0.1, kernel_p=None):\n",
        "        samples,features=x.shape\n",
        "        \n",
        "        y = np.copy(y)\n",
        "        x = self.normalization(x, set_value=True)\n",
        "        y = y.reshape([samples])  \n",
        "        Kernel = self.kernel(x, x)   \n",
        "        P = cp.Parameter(shape=Kernel.shape, value=Kernel, PSD=True)\n",
        "        P1 = np.ones(samples)\n",
        "        G = np.vstack((np.diag(np.ones(samples) * -1), np.identity(samples)))\n",
        "        h = np.hstack((np.zeros(samples), np.ones(samples) * c))\n",
        "        V1 = cp.Variable(samples)\n",
        "        V2 = cp.Variable(samples)\n",
        "        d = V1-V2\n",
        "        TT=V1+V2\n",
        "        prob = cp.Problem( cp.Minimize((1/2)*cp.quad_form(d, P) - y.T@d + eta*P1.T@(TT) ),\n",
        "                 [G@V1 <= h, G@V2 <= h, P1.T@d == 0.0])\n",
        "        prob.solve()\n",
        "        L  = np.ravel(d.value)\n",
        "        mask = np.abs(L) > 1e-5\n",
        "        L[np.invert(mask)] = 0\n",
        "        SVM_x = x[mask]\n",
        "        SVM_y = y[mask]\n",
        "        SVM_K = self.kernel(SVM_x, SVM_x)\n",
        "        L = L.reshape([-1, 1])\n",
        "        inter = np.mean(SVM_y - SVM_K.T@(L[mask]))\n",
        "        self.params = {'lagranges' : L[mask],'intercept':inter}\n",
        "        self.support_vector_machine = {'SVM_x': SVM_x}\n",
        "        \n",
        "        \n",
        "    def predict(self, X):\n",
        "        X = self.normalization(X)\n",
        "        L = self.params['lagranges']\n",
        "        inter = self.params['intercept']\n",
        "        SVM_x = self.support_vector_machine['SVM_x']\n",
        "        Kernel=self.kernel(SVM_x, X)\n",
        "        y=Kernel.T@L + inter\n",
        "        yy=y.reshape([-1])\n",
        "        return yy\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuCwPWdSucAH",
        "outputId": "8ed945e5-bcb9-4d16-fd64-9a2d8bf81f74"
      },
      "source": [
        "model=SVM()\n",
        "model.train(X_train,y_train,1000)\n",
        "y_pred = model.predict(X_test)\n",
        "df_res = pd.DataFrame({'y_test':y_test[:, 0], 'y_pred':y_pred})\n",
        "threshold = 0.5\n",
        "preds = [1 if val > threshold else 0 for val in df_res['y_pred']]\n",
        "print(accuracy_score(preds, df_res['y_test']))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjNxrPtsebd0"
      },
      "source": [
        "##NAIVE BAYESIAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQauEoQ1aGCg"
      },
      "source": [
        "import numpy as np\n",
        "     \n",
        "class NaiveBayesian:\n",
        "    \n",
        "    def training(self, X, Y):\n",
        "       \n",
        "    \n",
        "        self.label, count = np.unique(y, return_counts=True)\n",
        "        for x in X.T:\n",
        "          dd=np.unique(x)\n",
        "          self.x_classes = np.array(dd)\n",
        "      \n",
        "        self.phi_y = 1 * count/count.sum()\n",
        "        for k in self.label:\n",
        "          dd=X[Y==k].mean(axis=0)\n",
        "          self.u = np.array(dd)\n",
        "       \n",
        "        for k in self.label:\n",
        "          out3=X[Y==k].var(axis=0)+1\n",
        "          self.var_x = np.array(out3)\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        predicted=np.apply_along_axis(lambda x: self.compute_prob(x), 1, X)\n",
        "        return predicted\n",
        "    \n",
        "    def compute_prob(self, x):\n",
        "        AA=self.label[np.argmax(np.array(probs(self, x, Y)) for y in range(len(self.label)))]\n",
        "        return \n",
        "    \n",
        "    def probs(self, x, Y):\n",
        "        dd=self.var_x[Y]\n",
        "        R = 1/np.sqrt(2* np.pi * (dd))\n",
        "        o=(2 * self.var_x[Y])\n",
        "        out1=np.exp(-1* np.square(x - self.u[Y]) /o )\n",
        "        y1=np.prod(R *out1 )\n",
        "        return y1\n",
        "\n",
        "    def evaluate(self, x, Y):\n",
        "        predicted=self.predict(x)\n",
        "        ACC=(predicted == Y).mean()\n",
        "        return ACC"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m16ctfSYaMBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e842e7-4be9-4b83-9407-887a40332c6c"
      },
      "source": [
        "clf = NaiveBayesian().training(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('Accuracy Score:')\n",
        "print(clf.evaluate(X_test, df_res['y_test']))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:\n",
            "0.0\n"
          ]
        }
      ]
    }
  ]
}